{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2020-11-25T17:48:12.375361Z",
     "iopub.status.busy": "2020-11-25T17:48:12.374408Z",
     "iopub.status.idle": "2020-11-25T17:48:14.181038Z",
     "shell.execute_reply": "2020-11-25T17:48:14.179610Z"
    },
    "papermill": {
     "duration": 1.837752,
     "end_time": "2020-11-25T17:48:14.181210",
     "exception": false,
     "start_time": "2020-11-25T17:48:12.343458",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Importing Libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re\n",
    "import nltk\n",
    "nltk.download('stopwords') #downloads the required list of words that we need to remove\n",
    "from nltk.corpus import stopwords # importing 'stopwords' to this notebook\n",
    "from nltk.stem import WordNetLemmatizer # For Lemmitization\n",
    "\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036119,
     "end_time": "2020-11-25T17:48:14.255019",
     "exception": false,
     "start_time": "2020-11-25T17:48:14.218900",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Prepration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:48:14.338046Z",
     "iopub.status.busy": "2020-11-25T17:48:14.337170Z",
     "iopub.status.idle": "2020-11-25T17:48:14.384633Z",
     "shell.execute_reply": "2020-11-25T17:48:14.383906Z"
    },
    "papermill": {
     "duration": 0.093271,
     "end_time": "2020-11-25T17:48:14.384778",
     "exception": false,
     "start_time": "2020-11-25T17:48:14.291507",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1st Data\n",
    "data1= pd.read_csv('../input/stockmarket-sentiment-dataset/stock_data.csv')\n",
    "data1.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2020-11-25T17:48:14.468082Z",
     "iopub.status.busy": "2020-11-25T17:48:14.467354Z",
     "iopub.status.idle": "2020-11-25T17:48:14.734238Z",
     "shell.execute_reply": "2020-11-25T17:48:14.733588Z"
    },
    "papermill": {
     "duration": 0.311413,
     "end_time": "2020-11-25T17:48:14.734342",
     "exception": false,
     "start_time": "2020-11-25T17:48:14.422929",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text  Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...          1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...          1\n",
       "2  user I'd be afraid to short AMZN - they are lo...          1\n",
       "3                                  MNTA Over 12.00            1\n",
       "4                                   OI  Over 21.37            1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5786</th>\n",
       "      <td>Industry body CII said #discoms are likely to ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5787</th>\n",
       "      <td>#Gold prices slip below Rs 46,000 as #investor...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5788</th>\n",
       "      <td>Workers at Bajaj Auto have agreed to a 10% wag...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5789</th>\n",
       "      <td>#Sharemarket LIVE: Sensex off day’s high, up 6...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5790</th>\n",
       "      <td>#Sensex, #Nifty climb off day's highs, still u...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   Text  Sentiment\n",
       "5786  Industry body CII said #discoms are likely to ...          0\n",
       "5787  #Gold prices slip below Rs 46,000 as #investor...          0\n",
       "5788  Workers at Bajaj Auto have agreed to a 10% wag...          1\n",
       "5789  #Sharemarket LIVE: Sensex off day’s high, up 6...          1\n",
       "5790  #Sensex, #Nifty climb off day's highs, still u...          1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Changing (-1) to (0)\n",
    "for i in range(len(data1)):\n",
    "    if data1[\"Sentiment\"][i]== -1:\n",
    "        data1[\"Sentiment\"][i]= 0\n",
    "display(data1.head())\n",
    "display(data1.tail())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:48:14.798739Z",
     "iopub.status.busy": "2020-11-25T17:48:14.796223Z",
     "iopub.status.idle": "2020-11-25T17:48:14.803461Z",
     "shell.execute_reply": "2020-11-25T17:48:14.804015Z"
    },
    "papermill": {
     "duration": 0.042217,
     "end_time": "2020-11-25T17:48:14.804150",
     "exception": false,
     "start_time": "2020-11-25T17:48:14.761933",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text         False\n",
       "Sentiment    False\n",
       "dtype: bool"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking Null values\n",
    "data1.isnull().any()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:48:14.867118Z",
     "iopub.status.busy": "2020-11-25T17:48:14.866461Z",
     "iopub.status.idle": "2020-11-25T17:48:14.902928Z",
     "shell.execute_reply": "2020-11-25T17:48:14.902387Z"
    },
    "papermill": {
     "duration": 0.070817,
     "end_time": "2020-11-25T17:48:14.903041",
     "exception": false,
     "start_time": "2020-11-25T17:48:14.832224",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>neutral</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>neutral</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                               Text\n",
       "0   neutral  According to Gran , the company has no plans t...\n",
       "1   neutral  Technopolis plans to develop in stages an area..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2nd Data\n",
    "data2= pd.read_csv(\"../input/sentiment-analysis-for-financial-news/all-data.csv\", encoding='ISO-8859-1', header=None)\n",
    "data2.columns =['Sentiment' ,'Text']\n",
    "data2.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:48:14.980573Z",
     "iopub.status.busy": "2020-11-25T17:48:14.978669Z",
     "iopub.status.idle": "2020-11-25T17:48:15.668860Z",
     "shell.execute_reply": "2020-11-25T17:48:15.668328Z"
    },
    "papermill": {
     "duration": 0.737401,
     "end_time": "2020-11-25T17:48:15.668967",
     "exception": false,
     "start_time": "2020-11-25T17:48:14.931566",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>According to Gran , the company has no plans t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Technopolis plans to develop in stages an area...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>The international electronic industry company ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>With the new production plant the company woul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>According to the company 's updated strategy f...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Sentiment                                               Text\n",
       "0         2  According to Gran , the company has no plans t...\n",
       "1         2  Technopolis plans to develop in stages an area...\n",
       "2         0  The international electronic industry company ...\n",
       "3         1  With the new production plant the company woul...\n",
       "4         1  According to the company 's updated strategy f..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentiment</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4841</th>\n",
       "      <td>0</td>\n",
       "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4842</th>\n",
       "      <td>2</td>\n",
       "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4843</th>\n",
       "      <td>0</td>\n",
       "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4844</th>\n",
       "      <td>0</td>\n",
       "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4845</th>\n",
       "      <td>0</td>\n",
       "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Sentiment                                               Text\n",
       "4841         0  LONDON MarketWatch -- Share prices ended lower...\n",
       "4842         2  Rinkuskiai 's beer sales fell by 6.5 per cent ...\n",
       "4843         0  Operating profit fell to EUR 35.4 mn from EUR ...\n",
       "4844         0  Net sales of the Paper segment decreased to EU...\n",
       "4845         0  Sales in Finland decreased by 10.5 % in Januar..."
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Assigning label numbers\n",
    "for i in range(len(data2)):\n",
    "    if data2[\"Sentiment\"][i]== \"neutral\":\n",
    "        data2[\"Sentiment\"][i]= 2\n",
    "        \n",
    "    elif data2[\"Sentiment\"][i]== \"negative\":\n",
    "        data2[\"Sentiment\"][i]= 0\n",
    "        \n",
    "    elif data2[\"Sentiment\"][i]== \"positive\":\n",
    "        data2[\"Sentiment\"][i]= 1\n",
    "        \n",
    "display(data2.head())\n",
    "display(data2.tail())\n",
    "data2= data2[[\"Text\", \"Sentiment\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:48:15.736752Z",
     "iopub.status.busy": "2020-11-25T17:48:15.735928Z",
     "iopub.status.idle": "2020-11-25T17:48:15.754424Z",
     "shell.execute_reply": "2020-11-25T17:48:15.754999Z"
    },
    "papermill": {
     "duration": 0.056147,
     "end_time": "2020-11-25T17:48:15.755134",
     "exception": false,
     "start_time": "2020-11-25T17:48:15.698987",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text Sentiment\n",
       "0  Kickers on my watchlist XIDE TIT SOQ PNK CPW B...         1\n",
       "1  user: AAP MOVIE. 55% return for the FEA/GEED i...         1\n",
       "2  user I'd be afraid to short AMZN - they are lo...         1\n",
       "3                                  MNTA Over 12.00           1\n",
       "4                                   OI  Over 21.37           1"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10632</th>\n",
       "      <td>LONDON MarketWatch -- Share prices ended lower...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10633</th>\n",
       "      <td>Rinkuskiai 's beer sales fell by 6.5 per cent ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10634</th>\n",
       "      <td>Operating profit fell to EUR 35.4 mn from EUR ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10635</th>\n",
       "      <td>Net sales of the Paper segment decreased to EU...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10636</th>\n",
       "      <td>Sales in Finland decreased by 10.5 % in Januar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text Sentiment\n",
       "10632  LONDON MarketWatch -- Share prices ended lower...         0\n",
       "10633  Rinkuskiai 's beer sales fell by 6.5 per cent ...         2\n",
       "10634  Operating profit fell to EUR 35.4 mn from EUR ...         0\n",
       "10635  Net sales of the Paper segment decreased to EU...         0\n",
       "10636  Sales in Finland decreased by 10.5 % in Januar...         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Joining the 2 datasets\n",
    "data= pd.concat([data1, data2], axis=0, sort=False) # Joining date_lable and tops\n",
    "\n",
    "# Setting New Index for data_new\n",
    "data= data.set_index(i for i in range(0, len(data)))\n",
    "\n",
    "display(data.head())\n",
    "display(data.tail())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030394,
     "end_time": "2020-11-25T17:48:15.816990",
     "exception": false,
     "start_time": "2020-11-25T17:48:15.786596",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## To make the final classifier model suitable for new dataset(DJIA data), we will need to add those dataset text while creating corpus. Else it will give the following kind of error:\n",
    " **ValueError: Number of features of the model must match the input. Model n_features is 43 and input n_features is 2250** \n",
    " \n",
    " ## But during the sentiment training process, we dont want the DJIA data text. And hence we will remove it after creating corpus(X_selected will not contain DJIA data information) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:48:15.898491Z",
     "iopub.status.busy": "2020-11-25T17:48:15.887578Z",
     "iopub.status.idle": "2020-11-25T17:48:18.997673Z",
     "shell.execute_reply": "2020-11-25T17:48:18.997006Z"
    },
    "papermill": {
     "duration": 3.14993,
     "end_time": "2020-11-25T17:48:18.997816",
     "exception": false,
     "start_time": "2020-11-25T17:48:15.847886",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:38: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n"
     ]
    }
   ],
   "source": [
    "# Copying the whole preprocessing from \"DJIA News based performance\"\n",
    "\n",
    "data_DJIA= pd.read_csv('../input/stocknews/Combined_News_DJIA.csv')\n",
    "\n",
    "# Making 1 day past news uselful for next day\n",
    "date_label= data_DJIA[['Date', 'Label']]\n",
    "tops= data_DJIA.drop(columns= ['Date', 'Label'])\n",
    "\n",
    "date_label= date_label.loc[1:len(date_label)] # Removing 1st Date Entry\n",
    "tops=tops.loc[0:len(date_label)-1] # Removing last News Entry\n",
    "\n",
    "date_label= date_label.set_index(i for i in range(0, len(date_label))) # Setting Index for date_label\n",
    "tops= tops.set_index(i for i in range(0, len(tops))) # Setting Index for tops\n",
    "\n",
    "data_new= pd.concat([date_label, tops], axis=1, sort=False) # Joining date_lable and tops\n",
    "\n",
    "# Finding Missing Values\n",
    "miss_value_row_list=[]\n",
    "for i in tops.columns:\n",
    "    for j in range(len(data_new)):\n",
    "        if type(data_new[str(i)][j]) is str: # Non-missing values will have str type\n",
    "            continue\n",
    "        else: \n",
    "            miss_value_row_list.append(j)\n",
    "            \n",
    "    miss_value_row_list= list(set(miss_value_row_list)) # Removing repeating elements(row number) \n",
    "\n",
    "# Removing rows with missing entries\n",
    "data_new.drop(miss_value_row_list, inplace = True)\n",
    "\n",
    "# Setting New Index for data_new\n",
    "data_new= data_new.set_index(i for i in range(0, len(tops) - len(miss_value_row_list))) # After \n",
    "\n",
    "# Converting all the encoded news text(b'') to normal str \n",
    "for i in tops.columns:\n",
    "    for j in range(len(data_new)):\n",
    "        if data_new[str(i)][j][0]== 'b' and (data_new[str(i)][j][1]== '\"' or data_new[str(i)][j][1]==\"'\"): # It is encoded text if entry: b'_' or b\"_\"\n",
    "            data_new[str(i)][j]= data_new[str(i)][j][2:-1] # Removing b'' and b\"\"\n",
    "            \n",
    "# Combining all test of Top1, Top2..., Top25 in date-wise order  \n",
    "top25_news= []\n",
    "for i in range(len(data_new)):\n",
    "    news_list=[]\n",
    "    for j in tops.columns:\n",
    "        news= data_new[str(j)][i]\n",
    "        news_list.append(news)\n",
    "    news_list= ' '.join(news_list)\n",
    "    top25_news.append(news_list)\n",
    "    \n",
    "# Adding new column to data_new with all comments stacked tohgether for a particular date\n",
    "data_new.insert(2, \"Text\", top25_news) # As our sentiment data contains text in column named 'Text'\n",
    "\n",
    "# Creating a new dataset(data_final) with just the required columns\n",
    "data_all_news= data_new[[\"Date\", \"Label\", \"Text\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:48:19.066439Z",
     "iopub.status.busy": "2020-11-25T17:48:19.065661Z",
     "iopub.status.idle": "2020-11-25T17:48:19.070418Z",
     "shell.execute_reply": "2020-11-25T17:48:19.071156Z"
    },
    "papermill": {
     "duration": 0.042155,
     "end_time": "2020-11-25T17:48:19.071313",
     "exception": false,
     "start_time": "2020-11-25T17:48:19.029158",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1985,), (10637,))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_all_news[\"Text\"].shape, data['Text'].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.047492,
     "end_time": "2020-11-25T17:48:19.165913",
     "exception": false,
     "start_time": "2020-11-25T17:48:19.118421",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Hence we need to remove the 1985 elements from array**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:48:19.275295Z",
     "iopub.status.busy": "2020-11-25T17:48:19.267663Z",
     "iopub.status.idle": "2020-11-25T17:48:19.279314Z",
     "shell.execute_reply": "2020-11-25T17:48:19.278677Z"
    },
    "papermill": {
     "duration": 0.065199,
     "end_time": "2020-11-25T17:48:19.279416",
     "exception": false,
     "start_time": "2020-11-25T17:48:19.214217",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12622"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_corpus= pd.concat([data[['Text']], data_all_news[[\"Text\"]]], axis=0, sort=False) # Enclosing [[ ]] means we are assigning it as pd dataframe, not pd series\n",
    "for_corpus= for_corpus.set_index(i for i in range(0, len(data) + len(data_all_news)))\n",
    "len(for_corpus) # should be 10637 + 1985= 12622"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:48:19.358470Z",
     "iopub.status.busy": "2020-11-25T17:48:19.357598Z",
     "iopub.status.idle": "2020-11-25T17:48:19.363731Z",
     "shell.execute_reply": "2020-11-25T17:48:19.363115Z"
    },
    "papermill": {
     "duration": 0.051957,
     "end_time": "2020-11-25T17:48:19.363859",
     "exception": false,
     "start_time": "2020-11-25T17:48:19.311902",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Kickers on my watchlist XIDE TIT SOQ PNK CPW B...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>user: AAP MOVIE. 55% return for the FEA/GEED i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>user I'd be afraid to short AMZN - they are lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>MNTA Over 12.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>OI  Over 21.37</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12617</th>\n",
       "      <td>David Cameron to Resign as PM After EU Referen...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12618</th>\n",
       "      <td>Barclays and RBS shares suspended from trading...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12619</th>\n",
       "      <td>2,500 Scientists To Australia: If You Want To ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12620</th>\n",
       "      <td>Explosion At Airport In Istanbul Yemeni former...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12621</th>\n",
       "      <td>Jamaica proposes marijuana dispensers for tour...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>12622 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    Text\n",
       "0      Kickers on my watchlist XIDE TIT SOQ PNK CPW B...\n",
       "1      user: AAP MOVIE. 55% return for the FEA/GEED i...\n",
       "2      user I'd be afraid to short AMZN - they are lo...\n",
       "3                                      MNTA Over 12.00  \n",
       "4                                       OI  Over 21.37  \n",
       "...                                                  ...\n",
       "12617  David Cameron to Resign as PM After EU Referen...\n",
       "12618  Barclays and RBS shares suspended from trading...\n",
       "12619  2,500 Scientists To Australia: If You Want To ...\n",
       "12620  Explosion At Airport In Istanbul Yemeni former...\n",
       "12621  Jamaica proposes marijuana dispensers for tour...\n",
       "\n",
       "[12622 rows x 1 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for_corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032626,
     "end_time": "2020-11-25T17:48:19.429301",
     "exception": false,
     "start_time": "2020-11-25T17:48:19.396675",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:48:19.505844Z",
     "iopub.status.busy": "2020-11-25T17:48:19.503853Z",
     "iopub.status.idle": "2020-11-25T17:53:52.244635Z",
     "shell.execute_reply": "2020-11-25T17:53:52.244106Z"
    },
    "papermill": {
     "duration": 332.781932,
     "end_time": "2020-11-25T17:53:52.244749",
     "exception": false,
     "start_time": "2020-11-25T17:48:19.462817",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Cleanig all the news(stacked together)\n",
    "corpus=[]\n",
    "for i in range(len(for_corpus)):\n",
    "    news= re.sub('[^a-zA-Z]', ' ', for_corpus['Text'][i])\n",
    "    news= news.lower()\n",
    "    news= news.split()\n",
    "    news=[word for word in news if not word in set(stopwords.words('english'))]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    news=[lemmatizer.lemmatize(word)for word in news if not word in set(stopwords.words('english'))]\n",
    "    news= ' '.join(news)\n",
    "    corpus.append(news)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:53:52.329828Z",
     "iopub.status.busy": "2020-11-25T17:53:52.324726Z",
     "iopub.status.idle": "2020-11-25T17:53:53.964509Z",
     "shell.execute_reply": "2020-11-25T17:53:53.963975Z"
    },
    "papermill": {
     "duration": 1.685714,
     "end_time": "2020-11-25T17:53:53.964619",
     "exception": false,
     "start_time": "2020-11-25T17:53:52.278905",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Creating the TF-IDF model\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf = TfidfVectorizer(min_df=0.02, max_df=0.175, max_features = 50000, ngram_range = (1, 1))\n",
    "X = tfidf.fit_transform(corpus).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:53:54.036753Z",
     "iopub.status.busy": "2020-11-25T17:53:54.035708Z",
     "iopub.status.idle": "2020-11-25T17:53:54.041627Z",
     "shell.execute_reply": "2020-11-25T17:53:54.041093Z"
    },
    "papermill": {
     "duration": 0.04372,
     "end_time": "2020-11-25T17:53:54.041748",
     "exception": false,
     "start_time": "2020-11-25T17:53:53.998028",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12622"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:53:54.116633Z",
     "iopub.status.busy": "2020-11-25T17:53:54.115849Z",
     "iopub.status.idle": "2020-11-25T17:53:54.122072Z",
     "shell.execute_reply": "2020-11-25T17:53:54.121394Z"
    },
    "papermill": {
     "duration": 0.046237,
     "end_time": "2020-11-25T17:53:54.122173",
     "exception": false,
     "start_time": "2020-11-25T17:53:54.075936",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selecting only the sentiment analysis data, and removing the DJIA data\n",
    "'''\n",
    "    A the operation done while joining two dataframes was \n",
    "    pd.concat([data[['Text']], data_all_news[[\"Text\"]]].\n",
    "    This means the first 10637 entries were from sentiment\n",
    "    analyss data and the last 1985 were from DJIA data.\n",
    "    Hence we will slice the X and take first 10637 entries \n",
    "    for training and testing classifier.\n",
    "'''\n",
    "X_selected= X[:10637]\n",
    "len(X_selected)==len(data) # This will return true if the array is sliced just for sentiment data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:53:54.581188Z",
     "iopub.status.busy": "2020-11-25T17:53:54.195783Z",
     "iopub.status.idle": "2020-11-25T17:53:54.587020Z",
     "shell.execute_reply": "2020-11-25T17:53:54.586484Z"
    },
    "papermill": {
     "duration": 0.430688,
     "end_time": "2020-11-25T17:53:54.587130",
     "exception": false,
     "start_time": "2020-11-25T17:53:54.156442",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TFIDF_model.pkl']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving TF-IDF model for future\n",
    "joblib.dump(tfidf, 'TFIDF_model.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:53:54.661954Z",
     "iopub.status.busy": "2020-11-25T17:53:54.661226Z",
     "iopub.status.idle": "2020-11-25T17:53:54.667563Z",
     "shell.execute_reply": "2020-11-25T17:53:54.666682Z"
    },
    "papermill": {
     "duration": 0.046108,
     "end_time": "2020-11-25T17:53:54.667702",
     "exception": false,
     "start_time": "2020-11-25T17:53:54.621594",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 0, 0, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Target variable\n",
    "Y= data[\"Sentiment\"].values\n",
    "Y= Y.astype('int')\n",
    "display(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.052815,
     "end_time": "2020-11-25T17:53:54.773727",
     "exception": false,
     "start_time": "2020-11-25T17:53:54.720912",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:53:54.890331Z",
     "iopub.status.busy": "2020-11-25T17:53:54.889194Z",
     "iopub.status.idle": "2020-11-25T17:53:54.909137Z",
     "shell.execute_reply": "2020-11-25T17:53:54.908377Z"
    },
    "papermill": {
     "duration": 0.080125,
     "end_time": "2020-11-25T17:53:54.909271",
     "exception": false,
     "start_time": "2020-11-25T17:53:54.829146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Spliting Dataset into Training and Test sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test= train_test_split(X_selected, Y, test_size=0.10, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.051706,
     "end_time": "2020-11-25T17:53:55.016634",
     "exception": false,
     "start_time": "2020-11-25T17:53:54.964928",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Classification Algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:53:55.129137Z",
     "iopub.status.busy": "2020-11-25T17:53:55.128454Z",
     "iopub.status.idle": "2020-11-25T17:54:36.489429Z",
     "shell.execute_reply": "2020-11-25T17:54:36.488007Z"
    },
    "papermill": {
     "duration": 41.420311,
     "end_time": "2020-11-25T17:54:36.489530",
     "exception": false,
     "start_time": "2020-11-25T17:53:55.069219",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[121, 107,  31],\n",
       "       [ 72, 347, 100],\n",
       "       [ 10,  73, 203]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.723338485316847"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Random Forest\n",
    "from sklearn.ensemble import RandomForestClassifier \n",
    "classifier= RandomForestClassifier(n_estimators= 500, criterion= 'entropy', random_state= 0) \n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting the test set result\n",
    "y_pred= classifier.predict(X_test)\n",
    "display(y_pred)\n",
    "\n",
    "# Making the Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm= confusion_matrix(Y_test, y_pred)\n",
    "display(cm)\n",
    "\n",
    "Accuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "display(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:54:36.580003Z",
     "iopub.status.busy": "2020-11-25T17:54:36.579231Z",
     "iopub.status.idle": "2020-11-25T17:54:38.388182Z",
     "shell.execute_reply": "2020-11-25T17:54:38.387601Z"
    },
    "papermill": {
     "duration": 1.862321,
     "end_time": "2020-11-25T17:54:38.388301",
     "exception": false,
     "start_time": "2020-11-25T17:54:36.525980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[119, 112,  28],\n",
       "       [101, 340,  78],\n",
       "       [ 23,  98, 165]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.6830357142857143"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Decision Tree  \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "classifier= DecisionTreeClassifier(criterion= 'entropy', random_state= 0)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting the test set result\n",
    "y_pred= classifier.predict(X_test)\n",
    "display(y_pred)\n",
    "\n",
    "# Making the Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm= confusion_matrix(Y_test, y_pred)\n",
    "display(cm)\n",
    "\n",
    "Accuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "display(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:54:38.473887Z",
     "iopub.status.busy": "2020-11-25T17:54:38.473220Z",
     "iopub.status.idle": "2020-11-25T17:55:42.406328Z",
     "shell.execute_reply": "2020-11-25T17:55:42.404891Z"
    },
    "papermill": {
     "duration": 63.979604,
     "end_time": "2020-11-25T17:55:42.406431",
     "exception": false,
     "start_time": "2020-11-25T17:54:38.426827",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[112, 118,  29],\n",
       "       [ 55, 369,  95],\n",
       "       [  6,  78, 202]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.735474006116208"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Kernel SVM\n",
    "from sklearn.svm import SVC \n",
    "classifier= SVC(kernel='rbf', random_state= 0)\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting the test set result\n",
    "y_pred= classifier.predict(X_test)\n",
    "display(y_pred)\n",
    "\n",
    "# Making the Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm= confusion_matrix(Y_test, y_pred)\n",
    "display(cm)\n",
    "\n",
    "Accuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "display(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:55:42.500657Z",
     "iopub.status.busy": "2020-11-25T17:55:42.500016Z",
     "iopub.status.idle": "2020-11-25T17:55:42.913586Z",
     "shell.execute_reply": "2020-11-25T17:55:42.913043Z"
    },
    "papermill": {
     "duration": 0.465855,
     "end_time": "2020-11-25T17:55:42.913935",
     "exception": false,
     "start_time": "2020-11-25T17:55:42.448080",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 0, 1, 0])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[119, 112,  28],\n",
       "       [ 87, 355,  77],\n",
       "       [ 23,  93, 170]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7043090638930164"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# KNN\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier= KNeighborsClassifier(n_neighbors= 7, metric='minkowski', p=2, leaf_size=70, weights= 'distance', algorithm= 'brute')\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting the test set result\n",
    "y_pred= classifier.predict(X_test)\n",
    "display(y_pred)\n",
    "\n",
    "# Making the Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm= confusion_matrix(Y_test, y_pred)\n",
    "display(cm)\n",
    "\n",
    "Accuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "display(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:55:43.009972Z",
     "iopub.status.busy": "2020-11-25T17:55:43.009203Z",
     "iopub.status.idle": "2020-11-25T17:55:43.037443Z",
     "shell.execute_reply": "2020-11-25T17:55:43.036693Z"
    },
    "papermill": {
     "duration": 0.079395,
     "end_time": "2020-11-25T17:55:43.037563",
     "exception": false,
     "start_time": "2020-11-25T17:55:42.958168",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 1, ..., 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 75, 152,  32],\n",
       "       [ 39, 384,  96],\n",
       "       [  4, 103, 179]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7061538461538461"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Multinomial NB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier=MultinomialNB()\n",
    "classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting the test set result\n",
    "y_pred= classifier.predict(X_test)\n",
    "display(y_pred)\n",
    "\n",
    "# Making the Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm= confusion_matrix(Y_test, y_pred)\n",
    "display(cm)\n",
    "\n",
    "Accuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "display(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:55:43.137225Z",
     "iopub.status.busy": "2020-11-25T17:55:43.136497Z",
     "iopub.status.idle": "2020-11-25T17:55:47.029894Z",
     "shell.execute_reply": "2020-11-25T17:55:47.029117Z"
    },
    "papermill": {
     "duration": 3.945753,
     "end_time": "2020-11-25T17:55:47.030037",
     "exception": false,
     "start_time": "2020-11-25T17:55:43.084284",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 2, 1, ..., 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[ 92, 128,  39],\n",
       "       [ 51, 370,  98],\n",
       "       [  2,  86, 198]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7207488299531981"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# SGDC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "classifier = SGDClassifier(loss='modified_huber', random_state=0, shuffle=True)\n",
    "classifier = classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting the test set result\n",
    "y_pred= classifier.predict(X_test)\n",
    "display(y_pred)\n",
    "\n",
    "# Making the Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm= confusion_matrix(Y_test, y_pred)\n",
    "display(cm)\n",
    "\n",
    "Accuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "display(Accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:55:47.170092Z",
     "iopub.status.busy": "2020-11-25T17:55:47.169457Z",
     "iopub.status.idle": "2020-11-25T17:56:18.964623Z",
     "shell.execute_reply": "2020-11-25T17:56:18.963199Z"
    },
    "papermill": {
     "duration": 31.870826,
     "end_time": "2020-11-25T17:56:18.964739",
     "exception": false,
     "start_time": "2020-11-25T17:55:47.093913",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 2, 0, ..., 1, 1, 1])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[109, 131,  19],\n",
       "       [ 52, 406,  61],\n",
       "       [  0, 158, 128]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.7378223495702005"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Gradient Boosting\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "classifier = GradientBoostingClassifier()\n",
    "classifier = classifier.fit(X_train, Y_train)\n",
    "\n",
    "# Predicting the test set result\n",
    "y_pred= classifier.predict(X_test)\n",
    "display(y_pred)\n",
    "\n",
    "# Making the Confusion matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm= confusion_matrix(Y_test, y_pred)\n",
    "display(cm)\n",
    "\n",
    "Accuracy= (cm[0][0] + cm[1][1])/(cm[0][0] + cm[1][1] + cm[0][1] + cm[1][0])\n",
    "display(Accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046336,
     "end_time": "2020-11-25T17:56:19.058747",
     "exception": false,
     "start_time": "2020-11-25T17:56:19.012411",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    " Gradient Boosting Classifier gave the best test accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:56:19.179998Z",
     "iopub.status.busy": "2020-11-25T17:56:19.159816Z",
     "iopub.status.idle": "2020-11-25T17:56:19.187356Z",
     "shell.execute_reply": "2020-11-25T17:56:19.186831Z"
    },
    "papermill": {
     "duration": 0.080849,
     "end_time": "2020-11-25T17:56:19.187474",
     "exception": false,
     "start_time": "2020-11-25T17:56:19.106625",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['txt_sentiment.pkl']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Saving the GradientBoostingClassifier for future\n",
    "joblib.dump(classifier, \"txt_sentiment.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.046268,
     "end_time": "2020-11-25T17:56:19.281675",
     "exception": false,
     "start_time": "2020-11-25T17:56:19.235407",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Predicting Class Probablities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:56:19.379736Z",
     "iopub.status.busy": "2020-11-25T17:56:19.378903Z",
     "iopub.status.idle": "2020-11-25T17:56:19.390825Z",
     "shell.execute_reply": "2020-11-25T17:56:19.390302Z"
    },
    "papermill": {
     "duration": 0.063198,
     "end_time": "2020-11-25T17:56:19.390940",
     "exception": false,
     "start_time": "2020-11-25T17:56:19.327742",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# for probabilities\n",
    "l= classifier.predict_proba(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:56:19.492905Z",
     "iopub.status.busy": "2020-11-25T17:56:19.492054Z",
     "iopub.status.idle": "2020-11-25T17:56:19.499333Z",
     "shell.execute_reply": "2020-11-25T17:56:19.498500Z"
    },
    "papermill": {
     "duration": 0.060922,
     "end_time": "2020-11-25T17:56:19.499461",
     "exception": false,
     "start_time": "2020-11-25T17:56:19.438539",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.10366351, 0.23244337, 0.66389312])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.071105,
     "end_time": "2020-11-25T17:56:19.642368",
     "exception": false,
     "start_time": "2020-11-25T17:56:19.571263",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "**Classes:-** 0,1,2 i.e (negative), (positive), (nutral)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:56:19.793819Z",
     "iopub.status.busy": "2020-11-25T17:56:19.793147Z",
     "iopub.status.idle": "2020-11-25T17:56:19.798166Z",
     "shell.execute_reply": "2020-11-25T17:56:19.797407Z"
    },
    "papermill": {
     "duration": 0.084034,
     "end_time": "2020-11-25T17:56:19.798297",
     "exception": false,
     "start_time": "2020-11-25T17:56:19.714263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.10366351, 0.23244337, 0.66389312]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "l_1= classifier.predict_proba(X_test[1].reshape(1, -1))\n",
    "display(l_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:56:19.948496Z",
     "iopub.status.busy": "2020-11-25T17:56:19.947203Z",
     "iopub.status.idle": "2020-11-25T17:56:19.952857Z",
     "shell.execute_reply": "2020-11-25T17:56:19.952166Z"
    },
    "papermill": {
     "duration": 0.082621,
     "end_time": "2020-11-25T17:56:19.952985",
     "exception": false,
     "start_time": "2020-11-25T17:56:19.870364",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ True,  True,  True]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l_1==l[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2020-11-25T17:56:20.104707Z",
     "iopub.status.busy": "2020-11-25T17:56:20.103982Z",
     "iopub.status.idle": "2020-11-25T17:56:20.109628Z",
     "shell.execute_reply": "2020-11-25T17:56:20.109142Z"
    },
    "papermill": {
     "duration": 0.085399,
     "end_time": "2020-11-25T17:56:20.109748",
     "exception": false,
     "start_time": "2020-11-25T17:56:20.024349",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.10366351126920154"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k= classifier.predict_proba(X_test[1].reshape(1, -1))\n",
    "k[0][0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 492.346556,
   "end_time": "2020-11-25T17:56:20.268524",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2020-11-25T17:48:07.921968",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
